# Transformer Time Series Forecasting

Este repositorio contiene una implementaci√≥n completa de un modelo Transformer para predicci√≥n de series temporales, construido con TensorFlow y Keras. Se entrena sobre un dataset sint√©tico de precios burs√°tiles y se puede adaptar f√°cilmente a otros conjuntos de datos reales.

---

##  Descripci√≥n general del flujo en 8 pasos

### 1. **Generaci√≥n del Dataset Sint√©tico**
- Se simula una serie temporal con una tendencia lineal ascendente y ruido gaussiano.
- Se guarda como CSV para simular una carga real.

### 2. **Carga y Normalizaci√≥n**
- Se carga el archivo `stock_prices.csv`.
- Se aplica `MinMaxScaler` de Scikit-learn para escalar los valores al rango [0, 1].

### 3. **Preparaci√≥n del Dataset (Ventanas Temporales)**
- Se generan secuencias de 100 valores (`time_step`) y se asocia cada secuencia con su siguiente valor como etiqueta.
- Este proceso convierte una serie unidimensional en entradas `X` y salidas `Y` para el modelo.

### 4. **Definici√≥n de la Capa Multi-Head Attention**
- Se implementa manualmente la atenci√≥n con m√∫ltiples cabezas.
- Permite al modelo enfocar distintos contextos simult√°neamente dentro de la secuencia.

### 5. **Bloque Transformer y Encoder**
- Se define un `TransformerBlock` con atenci√≥n + red feedforward + normalizaci√≥n + dropout.
- Se apilan m√∫ltiples bloques para construir el `TransformerEncoder`.

### 6. **Construcci√≥n del Modelo Keras**
- Se define la arquitectura:
  - `Input` ‚Üí `Dense` ‚Üí `TransformerEncoder` ‚Üí `Flatten` ‚Üí `Dropout` ‚Üí `Dense` (salida).
- Se compila con `Adam` y `loss='mse'` (regresi√≥n).

### 7. **Entrenamiento**
- El modelo se entrena durante 20 √©pocas con `batch_size=32`.
- Puedes modificar el `batch_size` para observar cambios en estabilidad y velocidad.

### 8. **Predicci√≥n y Visualizaci√≥n**
- Se invierte la normalizaci√≥n (`inverse_transform`) para comparar con los valores originales.
- Se grafica la serie real y la predicci√≥n en un mismo gr√°fico con `matplotlib`.

---

##  ¬øQu√© es una ventana temporal?

Una ventana temporal es una forma de preparar los datos para que el modelo pueda aprender relaciones temporales. Por ejemplo:

```text
Input (X):  [ d√≠a 1 ‚Üí d√≠a 100 ]
Label (Y):         d√≠a 101
```

Con `time_step=100`, el modelo ve 100 valores pasados y aprende a predecir el siguiente.

---

##  C√≥mo probar el modelo

### 1. Instala los requisitos:
```bash
pip install numpy pandas scikit-learn tensorflow matplotlib
```

### 2. Ejecuta el script:
```bash
python transformer_stock_forecast.py
```

Esto:
- Generar√° el dataset
- Entrenar√° el modelo
- Mostrar√° el gr√°fico comparativo entre predicci√≥n y valores reales

---

##  C√≥mo adaptar el c√≥digo a otro dataset

1. **Reemplaza `stock_prices.csv` por tu propio archivo** que contenga una columna num√©rica con la serie temporal.

2. Aseg√∫rate de cambiar esta l√≠nea:
```python
data = data[['Close']].values  # cambia 'Close' por tu columna
```

3. El resto del flujo funcionar√° igual si:
   - Tu serie es continua (por ejemplo, temperaturas, consumo, etc.)
   - Tiene suficientes muestras (m√≠nimo 200‚Äì300 para pruebas)

### ‚ùó Consideraciones clave:
- Escala siempre los datos antes de entrenar.
- Ajusta `time_step` si quieres que el modelo observe m√°s o menos contexto.
- Eval√∫a visualmente la predicci√≥n para detectar overfitting.

---

## ‚úèÔ∏è Modificaciones √∫tiles

- Puedes cambiar la funci√≥n de activaci√≥n final a `tanh` si tus datos est√°n centrados:
```python
outputs = Dense(1, activation='tanh')(x)
```

- Tambi√©n puedes usar `validation_split=0.2` durante `model.fit(...)` para evaluar generalizaci√≥n.

---

## üìå Cr√©ditos

Creado para pr√°cticas de aprendizaje profundo con Transformers aplicados a series temporales.\
